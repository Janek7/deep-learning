{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a4476f",
   "metadata": {},
   "source": [
    "# SVHN Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf05b0",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce8d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# TEAM MEMBERS:\n",
    "# Antonio Krizmanic - 2b193238-8e3c-11ec-986f-f39926f24a9c\n",
    "# Janek Putz - e31a3cae-8e6c-11ec-986f-f39926f24a9c\n",
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default\n",
    "logger = logging.getLogger('SVHN')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import bboxes_utils\n",
    "import efficient_net\n",
    "from svhn_dataset import SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52e00ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--batch_size\", default=50, type=int, help=\"Batch size.\")\n",
    "parser.add_argument(\"--epochs\", default=1, type=int, help=\"Number of epochs.\")\n",
    "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\n",
    "parser.add_argument(\"--threads\", default=1, type=int, help=\"Maximum number of threads to use.\")\n",
    "\n",
    "parser.add_argument(\"--logging_level\", default=\"info\", type=str, help=\"Logging level\")\n",
    "parser.add_argument(\"--fine_tuning\", default=False, type=bool, help=\"Optionally fine tune the efficient net core.\")\n",
    "parser.add_argument(\"--image_size\", default=224, type=int, help=\"Width and height to resize image to uniform size.\")\n",
    "parser.add_argument(\"--iou_threshold\", default=0.5, type=float, help=\"Threshold to assign anchors to gold bboxes.\")\n",
    "\n",
    "parser.add_argument(\"--batch_norm\", default=True, type=bool, help=\"Batch normalization of conv. layers.\")\n",
    "parser.add_argument(\"--l2\", default=0.00, type=float, help=\"L2 regularization.\")\n",
    "parser.add_argument(\"--decay\", default=\"None\", type=str, help=\"Learning decay rate type\")\n",
    "parser.add_argument(\"--learning_rate\", default=0.001, type=float, help=\"Initial learning rate.\")\n",
    "parser.add_argument(\"--learning_rate_final\", default=0.0001, type=float, help=\"Final learning rate.\")\n",
    "\n",
    "# todo: try batch=1 without resizing\n",
    "\n",
    "\n",
    "args = parser.parse_args([] if \"__file__\" not in globals() else None)\n",
    "\n",
    "# Create logdir name\n",
    "args.logdir = os.path.join(\"logs\", \"{}-{}-{}\".format(\n",
    "    os.path.basename(globals().get(\"__file__\", \"notebook\")),\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\"),\n",
    "    \",\".join((\"{}={}\".format(re.sub(\"(.)[^_]*_?\", r\"\\1\", k), v) for k, v in sorted(vars(args).items())))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d031ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seeds and threads\n",
    "np.random.seed(args.seed)\n",
    "tf.random.set_seed(args.seed)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(args.threads)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(args.threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d57664",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53925b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "svhn = SVHN()\n",
    "\n",
    "# create anchors\n",
    "# TODO: create different ratios and sizes\n",
    "anchors = np.array([[-1, -1, -1, -1]])\n",
    "for T in range(0, 85, 14):\n",
    "    for L in range(0, 99, 7):\n",
    "        anchors = np.append(anchors, [[T, L, T + 28, L + 14]], axis=0)\n",
    "anchors = np.delete(anchors, 0, 0)\n",
    "\n",
    "def create_dataset(dataset: tf.data.Dataset, training: bool) -> tf.data.Dataset:\n",
    "\n",
    "    def prepare_data(example):\n",
    "        example[\"classes\"] = tf.cast(example[\"classes\"], dtype=tf.int32)\n",
    "        # resizing\n",
    "        #print(type(example[\"image\"]))\n",
    "        #print(tf.shape(example[\"image\"])[0])\n",
    "        example[\"bboxes\"] = example[\"bboxes\"] * (tf.cast(tf.shape(example[\"image\"])[0], tf.float32) / args.image_size)\n",
    "        resized_image = tf.image.resize(example[\"image\"], [args.image_size, args.image_size])\n",
    "        # \n",
    "        anchor_classes, anchor_bboxes = tf.numpy_function(\n",
    "            bboxes_utils.bboxes_training, # name\n",
    "            [anchors, example[\"classes\"], example[\"bboxes\"], args.iou_threshold], # param values\n",
    "            (tf.int32, tf.float32) # return types\n",
    "        )\n",
    "        \n",
    "        output = {\n",
    "            \"classes\": example[\"classes\"],\n",
    "            \"bboxes\": tf.ensure_shape(anchor_bboxes, [len(anchors), 4])\n",
    "        }\n",
    "        return resized_image, output\n",
    "\n",
    "    dataset = dataset.map(prepare_data)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size=10000, seed=args.seed)\n",
    "    dataset = dataset.batch(args.batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b30cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_dataset(svhn.train, True)\n",
    "dev = create_dataset(svhn.dev, False)\n",
    "test = create_dataset(svhn.test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390d9f63",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d2bd3e",
   "metadata": {},
   "source": [
    "### Load EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83e7ab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1280), dtype=tf.float32, name=None), name='avg_pool/Mean:0', description=\"created by layer 'avg_pool'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 1280), dtype=tf.float32, name=None), name='top_activation/IdentityN:0', description=\"created by layer 'top_activation'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 112), dtype=tf.float32, name=None), name='block5c_add/add:0', description=\"created by layer 'block5c_add'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 40), dtype=tf.float32, name=None), name='block3b_add/add:0', description=\"created by layer 'block3b_add'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 24), dtype=tf.float32, name=None), name='block2b_add/add:0', description=\"created by layer 'block2b_add'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 112, 112, 16), dtype=tf.float32, name=None), name='block1a_project_bn/FusedBatchNormV3:0', description=\"created by layer 'block1a_project_bn'\")\n"
     ]
    }
   ],
   "source": [
    "# change dynamic_input_shape in case of batching with size 1 and different sizes\n",
    "efficientnet_b0 = efficient_net.pretrained_efficientnet_b0(include_top=False, dynamic_input_shape=False)\n",
    "efficientnet_b0.trainable = args.fine_tuning\n",
    "for o in efficientnet_b0.outputs:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0aead0",
   "metadata": {},
   "source": [
    "### Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6710765",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.l2:\n",
    "    regularizer = tf.keras.regularizers.L2(args.l2)\n",
    "else:\n",
    "    regularizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0281e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_relu(input):\n",
    "    if args.batch_norm:\n",
    "        return tf.keras.layers.ReLU()(tf.keras.layers.BatchNormalization()(input))\n",
    "    else:\n",
    "        return tf.keras.layers.ReLU()(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdd705cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.decay or args.decay in [\"None\", \"none\"]:\n",
    "    learning_rate = args.learning_rate\n",
    "else:\n",
    "    decay_steps = (len(train) / args.batch_size) * args.epochs\n",
    "    if args.decay == 'linear':\n",
    "        learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(decay_steps=decay_steps,\n",
    "                                                                      initial_learning_rate=args.learning_rate,\n",
    "                                                                      end_learning_rate=args.learning_rate_final,\n",
    "                                                                      power=1.0)\n",
    "    elif args.decay == 'exponential':\n",
    "        decay_rate = args.learning_rate_final / args.learning_rate\n",
    "        learning_rate = tf.optimizers.schedules.ExponentialDecay(decay_steps=decay_steps,\n",
    "                                                                 decay_rate=decay_rate,\n",
    "                                                                 initial_learning_rate=args.learning_rate)\n",
    "    elif args.decay == 'cosine':\n",
    "        learning_rate = tf.keras.optimizers.schedules.CosineDecay(decay_steps=decay_steps,\n",
    "                                                                  initial_learning_rate=args.learning_rate)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Use only 'linear', 'exponential' or 'cosine' as LR scheduler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4cfbe7",
   "metadata": {},
   "source": [
    "### Compose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fbe52be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " efficientnet-b0 (Functional)   [(None, 1280),       4049564     ['input_24[0][0]']               \n",
      "                                 (None, 7, 7, 1280)                                               \n",
      "                                , (None, 14, 14, 11                                               \n",
      "                                2),                                                               \n",
      "                                 (None, 28, 28, 40)                                               \n",
      "                                , (None, 56, 56, 24                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 112, 112, 1                                               \n",
      "                                6)]                                                               \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 14, 14, 256)  258304      ['efficientnet-b0[7][2]']        \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 14, 14, 256)  258304      ['efficientnet-b0[7][2]']        \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 14, 14, 256)  590080      ['re_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 14, 14, 256)  590080      ['re_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 14, 14, 4)    1028        ['re_lu_33[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 14, 14, 10)   2570        ['re_lu_31[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,754,026\n",
      "Trainable params: 1,702,414\n",
      "Non-trainable params: 4,051,612\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(args.image_size, args.image_size, 3))\n",
    "\n",
    "pyramid_output = efficientnet_b0(inputs)[2]\n",
    "\n",
    "# classification head (TODO: try more layers)\n",
    "classes_conv1 = bn_relu(tf.keras.layers.Conv2D(256, 3, 1, \"same\", kernel_regularizer=regularizer)(pyramid_output))\n",
    "classes_conv2 = bn_relu(tf.keras.layers.Conv2D(256, 3, 1, \"same\", kernel_regularizer=regularizer)(classes_conv1))\n",
    "classes_output = tf.keras.layers.Dense(SVHN.LABELS, activation=tf.nn.softmax, kernel_regularizer=regularizer)(classes_conv2)\n",
    "\n",
    "# bbox regression head (TODO: try more layers)\n",
    "bbox_conv1 = bn_relu(tf.keras.layers.Conv2D(256, 3, 1, \"same\", kernel_regularizer=regularizer)(pyramid_output))\n",
    "bbox_conv2 = bn_relu(tf.keras.layers.Conv2D(256, 3, 1, \"same\", kernel_regularizer=regularizer)(bbox_conv1))\n",
    "bbox_output = tf.keras.layers.Dense(4, activation=tf.nn.relu)(bbox_conv2)\n",
    "\n",
    "outputs = {\n",
    "    \"classes\": classes_output,\n",
    "    \"bboxes\": bbox_output\n",
    "}\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss={  # keys fit to output dict\n",
    "        \"classes\": tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        \"bboxes\": tfa.losses.SigmoidFocalCrossEntropy(alpha=0.25, gamma=2)\n",
    "    },\n",
    "    metrics={\n",
    "        \"classes\": [tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")],\n",
    "        \"bboxes\": []  # TODO\n",
    "    }\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b92a1",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1dc33041",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow_addons\\utils\\keras_utils.py\", line 61, in call  *\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow_addons\\losses\\focal_loss.py\", line 121, in sigmoid_focal_crossentropy  *\n        ce = K.binary_crossentropy(y_true, y_pred, from_logits=from_logits)\n    File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\keras\\backend.py\", line 5262, in binary_crossentropy\n        bce = target * tf.math.log(output + epsilon())\n\n    ValueError: Dimensions must be equal, but are 105 and 14 for '{{node mul}} = Mul[T=DT_FLOAT](y_true, Log)' with input shapes: [?,105,4], [?,14,14,4].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m best_checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mlogdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcags_classification.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorBoard\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistogram_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_checkpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow_addons\\utils\\keras_utils.py\", line 61, in call  *\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow_addons\\losses\\focal_loss.py\", line 121, in sigmoid_focal_crossentropy  *\n        ce = K.binary_crossentropy(y_true, y_pred, from_logits=from_logits)\n    File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\keras\\backend.py\", line 5262, in binary_crossentropy\n        bce = target * tf.math.log(output + epsilon())\n\n    ValueError: Dimensions must be equal, but are 105 and 14 for '{{node mul}} = Mul[T=DT_FLOAT](y_true, Log)' with input shapes: [?,105,4], [?,14,14,4].\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint_path = os.path.join(args.logdir, \"cags_classification.ckpt\")\n",
    "model.fit(\n",
    "    train, batch_size=args.batch_size, epochs=args.epochs, validation_data=dev,\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(args.logdir, histogram_freq=1, update_freq=100, profile_batch=0),\n",
    "               tf.keras.callbacks.ModelCheckpoint(filepath=best_checkpoint_path, save_weights_only=False,\n",
    "                                                  monitor='val_accuracy', mode='max', save_best_only=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b31a57d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nValueError: attempt to get argmax of an empty sequence\nTraceback (most recent call last):\n\n  File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\janek\\Development\\Git\\Prag\\deep-learning-lecture\\06_object_detection\\bboxes_utils.py\", line 165, in bboxes_training\n    max_iou_idx = np.argmax(iou_comparisons)\n\n  File \"<__array_function__ internals>\", line 5, in argmax\n\n  File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 1195, in argmax\n    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n\n  File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 57, in _wrapfunc\n    return bound(*args, **kwds)\n\nValueError: attempt to get argmax of an empty sequence\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_predict_function_62565]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m test_test_set \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_test_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nValueError: attempt to get argmax of an empty sequence\nTraceback (most recent call last):\n\n  File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\janek\\Development\\Git\\Prag\\deep-learning-lecture\\06_object_detection\\bboxes_utils.py\", line 165, in bboxes_training\n    max_iou_idx = np.argmax(iou_comparisons)\n\n  File \"<__array_function__ internals>\", line 5, in argmax\n\n  File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 1195, in argmax\n    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n\n  File \"C:\\Users\\janek\\anaconda3\\envs\\dl-lecture\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 57, in _wrapfunc\n    return bound(*args, **kwds)\n\nValueError: attempt to get argmax of an empty sequence\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_predict_function_62565]"
     ]
    }
   ],
   "source": [
    "test_test_set = test.take(1)\n",
    "prediction = model.predict(test_test_set)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d561cb8a",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use tf.image.non_max_suppression here? I think so w.r.t slide 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set annotations, but in `args.logdir` to allow parallel execution.\n",
    "os.makedirs(args.logdir, exist_ok=True)\n",
    "with open(os.path.join(args.logdir, \"svhn_competition.txt\"), \"w\", encoding=\"utf-8\") as predictions_file:\n",
    "    # TODO: Predict the digits and their bounding boxes on the test set.\n",
    "    # Assume that for a single test image we get\n",
    "    # - `predicted_classes`: a 1D array with the predicted digits,\n",
    "    # - `predicted_bboxes`: a [len(predicted_classes), 4] array with bboxes;\n",
    "    for predicted_classes, predicted_bboxes in ...:\n",
    "        output = []\n",
    "        for label, bbox in zip(predicted_classes, predicted_bboxes):\n",
    "            output += [label] + list(bbox)\n",
    "        print(*output, file=predictions_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
